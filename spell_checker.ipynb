{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oTDWF9-9WFf",
        "outputId": "d99ff431-9ce1-4ffd-b9b0-425a5a19a7b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXNyzm4dRik1",
        "outputId": "4a4b4d2d-acad-41a7-b726-b5cb108ecefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
            "\n",
            "java \n",
            "\n",
            "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
          ]
        }
      ],
      "source": [
        "with open(\"data/artigos.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    articles = f.read()\n",
        "\n",
        "print(articles[:500])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splited_words = nltk.tokenize.word_tokenize(articles)"
      ],
      "metadata": {
        "id": "tbJ6zpKM9HkU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splited_words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkroQWI--GrP",
        "outputId": "321ff0c5-feb9-4111-bb86-2f32872b561e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imagem',\n",
              " 'Temos',\n",
              " 'a',\n",
              " 'seguinte',\n",
              " 'classe',\n",
              " 'que',\n",
              " 'representa',\n",
              " 'um',\n",
              " 'usuário',\n",
              " 'no']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_words(token_list):\n",
        "    words_list = []\n",
        "    for token in token_list:\n",
        "        if token.isalpha():\n",
        "            words_list.append(token)\n",
        "    return words_list"
      ],
      "metadata": {
        "id": "AmA3P0Kj-03q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_list = split_words(splited_words)\n",
        "print(f\"The number of words is {len(words_list)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shkagIhu_n3f",
        "outputId": "b312bd51-b4e5-41c2-bb43-3427df8bf5cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words is 403031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(words_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsSW3yVyBcSv",
        "outputId": "09a1d557-b87e-4a23-8ea3-d1335ac37a98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(words_list):\n",
        "    normalized_list = []\n",
        "    for word in words_list:\n",
        "        normalized_list.append(word.lower())\n",
        "    return normalized_list"
      ],
      "metadata": {
        "id": "vkxagMqxBjTm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_list = normalize(words_list)\n",
        "print(normalized_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRXKthCXB-SJ",
        "outputId": "1ed2aff8-272d-4fca-a46e-8d1ad6198c66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letters(slices):\n",
        "    new_words = []\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "    for L, R in slices:    \n",
        "        for letter in letters:\n",
        "            new_words.append(L + letter + R)\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "p85IykeC8p5O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deleting_character(slices):\n",
        "    new_words = []\n",
        "    for L, R in slices:    \n",
        "        new_words.append(L + R[1:])\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "XFkMir0hQLna"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_letter(slices):\n",
        "    new_words = []\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "    for L, R in slices:    \n",
        "        for letter in letters:\n",
        "            new_words.append(L + letter + R[1:])\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "6-EekqqKIkIk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_letter(slices):\n",
        "    new_words = []\n",
        "    for L, R in slices:    \n",
        "        if len(R) > 1:\n",
        "            new_words.append(L + R[1] + R[0] + R[2:])\n",
        "\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "RCe9SW22LMFn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_generator(word):\n",
        "    slices = []\n",
        "    for i in range(len(word)+1):\n",
        "        slices.append((word[:i], word[i:]))\n",
        "    generated_words = insert_letters(slices)\n",
        "    generated_words += deleting_character(slices)\n",
        "    generated_words += change_letter(slices)\n",
        "    generated_words += invert_letter(slices)\n",
        "    return generated_words"
      ],
      "metadata": {
        "id": "7FNhj-hPDM2I"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_example = \"lgica\"\n",
        "generated_words = word_generator(word_example)\n",
        "print(generated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJgiaLgq-7QF",
        "outputId": "336be05b-0f7b-4ed2-bfb9-4c8dde272955"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç', 'gica', 'lica', 'lgca', 'lgia', 'lgic', 'lgica', 'agica', 'bgica', 'cgica', 'dgica', 'egica', 'fgica', 'ggica', 'hgica', 'igica', 'jgica', 'kgica', 'lgica', 'mgica', 'ngica', 'ogica', 'pgica', 'qgica', 'rgica', 'sgica', 'tgica', 'ugica', 'vgica', 'wgica', 'xgica', 'ygica', 'zgica', 'àgica', 'ágica', 'âgica', 'ãgica', 'ègica', 'égica', 'êgica', 'ìgica', 'ígica', 'îgica', 'ògica', 'ógica', 'ôgica', 'õgica', 'ùgica', 'úgica', 'ûgica', 'çgica', 'laica', 'lbica', 'lcica', 'ldica', 'leica', 'lfica', 'lgica', 'lhica', 'liica', 'ljica', 'lkica', 'llica', 'lmica', 'lnica', 'loica', 'lpica', 'lqica', 'lrica', 'lsica', 'ltica', 'luica', 'lvica', 'lwica', 'lxica', 'lyica', 'lzica', 'làica', 'láica', 'lâica', 'lãica', 'lèica', 'léica', 'lêica', 'lìica', 'líica', 'lîica', 'lòica', 'lóica', 'lôica', 'lõica', 'lùica', 'lúica', 'lûica', 'lçica', 'lgaca', 'lgbca', 'lgcca', 'lgdca', 'lgeca', 'lgfca', 'lggca', 'lghca', 'lgica', 'lgjca', 'lgkca', 'lglca', 'lgmca', 'lgnca', 'lgoca', 'lgpca', 'lgqca', 'lgrca', 'lgsca', 'lgtca', 'lguca', 'lgvca', 'lgwca', 'lgxca', 'lgyca', 'lgzca', 'lgàca', 'lgáca', 'lgâca', 'lgãca', 'lgèca', 'lgéca', 'lgêca', 'lgìca', 'lgíca', 'lgîca', 'lgòca', 'lgóca', 'lgôca', 'lgõca', 'lgùca', 'lgúca', 'lgûca', 'lgçca', 'lgiaa', 'lgiba', 'lgica', 'lgida', 'lgiea', 'lgifa', 'lgiga', 'lgiha', 'lgiia', 'lgija', 'lgika', 'lgila', 'lgima', 'lgina', 'lgioa', 'lgipa', 'lgiqa', 'lgira', 'lgisa', 'lgita', 'lgiua', 'lgiva', 'lgiwa', 'lgixa', 'lgiya', 'lgiza', 'lgiàa', 'lgiáa', 'lgiâa', 'lgiãa', 'lgièa', 'lgiéa', 'lgiêa', 'lgiìa', 'lgiía', 'lgiîa', 'lgiòa', 'lgióa', 'lgiôa', 'lgiõa', 'lgiùa', 'lgiúa', 'lgiûa', 'lgiça', 'lgica', 'lgicb', 'lgicc', 'lgicd', 'lgice', 'lgicf', 'lgicg', 'lgich', 'lgici', 'lgicj', 'lgick', 'lgicl', 'lgicm', 'lgicn', 'lgico', 'lgicp', 'lgicq', 'lgicr', 'lgics', 'lgict', 'lgicu', 'lgicv', 'lgicw', 'lgicx', 'lgicy', 'lgicz', 'lgicà', 'lgicá', 'lgicâ', 'lgicã', 'lgicè', 'lgicé', 'lgicê', 'lgicì', 'lgicí', 'lgicî', 'lgicò', 'lgicó', 'lgicô', 'lgicõ', 'lgicù', 'lgicú', 'lgicû', 'lgicç', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç', 'glica', 'ligca', 'lgcia', 'lgiac']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = nltk.FreqDist(normalized_list)\n",
        "frequency.most_common(10)\n",
        "\n",
        "words_total = len(normalized_list)"
      ],
      "metadata": {
        "id": "NQ0h4gGTBTDD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def probability(generated_word):\n",
        "    return frequency[generated_word]/words_total"
      ],
      "metadata": {
        "id": "apAd_0SIBuid"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checker(word):\n",
        "    generated_words = word_generator(word)\n",
        "    right_word = max(generated_words, key=probability)\n",
        "    return right_word"
      ],
      "metadata": {
        "id": "iURAsGyM_-GU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checker(word_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rXLvNOdrCoha",
        "outputId": "66159f85-d948-409b-df97-cd9826c10503"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lógica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_data(file_name):\n",
        "    words_test_list = []\n",
        "    f = open(file_name, \"r\")\n",
        "    for line in f:\n",
        "        right, wrong = line.split()\n",
        "        words_test_list.append((right, wrong))\n",
        "    f.close()\n",
        "    return words_test_list"
      ],
      "metadata": {
        "id": "o6FjxuyYHmNw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = create_test_data(\"data/palavras.txt\")\n",
        "test_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npxwb3CsIlP7",
        "outputId": "b7705416-3bb4-46fe-ad8d-cc6b139a18fd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('podemos', 'pyodemos'),\n",
              " ('esse', 'esje'),\n",
              " ('já', 'jrá'),\n",
              " ('nosso', 'nossov'),\n",
              " ('são', 'sãêo'),\n",
              " ('dos', 'dosa'),\n",
              " ('muito', 'muifo'),\n",
              " ('imagem', 'iômagem'),\n",
              " ('sua', 'ósua'),\n",
              " ('também', 'tambéùm'),\n",
              " ('ele', 'eme'),\n",
              " ('fazer', 'èazer'),\n",
              " ('temos', 'temfs'),\n",
              " ('essa', 'eàssa'),\n",
              " ('quando', 'quaôdo'),\n",
              " ('vamos', 'vamvos'),\n",
              " ('sobre', 'hsobre'),\n",
              " ('java', 'sjava'),\n",
              " ('das', 'daõs'),\n",
              " ('agora', 'agorah'),\n",
              " ('está', 'eòtá'),\n",
              " ('cada', 'céda'),\n",
              " ('mesmo', 'zmesmo'),\n",
              " ('nos', 'noâ'),\n",
              " ('forma', 'fobma'),\n",
              " ('seja', 'sejéa'),\n",
              " ('então', 'enêão'),\n",
              " ('criar', 'èriar'),\n",
              " ('código', 'cóeigo'),\n",
              " ('caso', 'casío'),\n",
              " ('exemplo', 'áexemplo'),\n",
              " ('tem', 'tĩem'),\n",
              " ('usuário', 'usuárôio'),\n",
              " ('dados', 'dfados'),\n",
              " ('python', 'pgthon'),\n",
              " ('nossa', 'nossah'),\n",
              " ('além', 'alémè'),\n",
              " ('assim', 'asõim'),\n",
              " ('ter', 'teb'),\n",
              " ('até', 'atĩ'),\n",
              " ('bem', 'âem'),\n",
              " ('design', 'desigen'),\n",
              " ('trabalho', 'trabalàho'),\n",
              " ('foi', 'foo'),\n",
              " ('apenas', 'apenaũ'),\n",
              " ('empresa', 'empresà'),\n",
              " ('valor', 'valíor'),\n",
              " ('será', 'serr'),\n",
              " ('entre', 'entke'),\n",
              " ('método', 'méqodo'),\n",
              " ('precisamos', 'precisamops'),\n",
              " ('ainda', 'ainàa'),\n",
              " ('vai', 'van'),\n",
              " ('conteúdo', 'ûconteúdo'),\n",
              " ('seus', 'çeus'),\n",
              " ('eu', 'eû'),\n",
              " ('todos', 'todtos'),\n",
              " ('tempo', 'temeo'),\n",
              " ('sempre', 'semre'),\n",
              " ('qual', 'quakl'),\n",
              " ('ela', 'elaá'),\n",
              " ('só', 'síó'),\n",
              " ('utilizar', 'utiqizar'),\n",
              " ('projeto', 'prhojeto'),\n",
              " ('site', 'siàe'),\n",
              " ('sem', 'seém'),\n",
              " ('pelo', 'peln'),\n",
              " ('alura', 'aléra'),\n",
              " ('dia', 'tdia'),\n",
              " ('tudo', 'tuúo'),\n",
              " ('podemos', 'kpodemos'),\n",
              " ('esse', 'eẽsse'),\n",
              " ('já', 'jé'),\n",
              " ('nosso', 'nçosso'),\n",
              " ('são', 'sãô'),\n",
              " ('dos', 'odos'),\n",
              " ('muito', 'tuito'),\n",
              " ('imagem', 'imõgem'),\n",
              " ('sua', 'siua'),\n",
              " ('também', 'tamvbém'),\n",
              " ('ele', 'elpe'),\n",
              " ('fazer', 'façzer'),\n",
              " ('temos', 'teos'),\n",
              " ('essa', 'eũsa'),\n",
              " ('quando', 'quaìdo'),\n",
              " ('vamos', 'vjmos'),\n",
              " ('sobre', 'sxobre'),\n",
              " ('java', 'jkva'),\n",
              " ('das', 'dms'),\n",
              " ('agora', 'agtora'),\n",
              " ('está', 'esútá'),\n",
              " ('cada', 'cava'),\n",
              " ('mesmo', 'medmo'),\n",
              " ('nos', 'ános'),\n",
              " ('forma', 'forûa'),\n",
              " ('seja', 'smeja'),\n",
              " ('então', 'enjtão'),\n",
              " ('criar', 'criôar'),\n",
              " ('código', 'cóàigo'),\n",
              " ('caso', 'èaso'),\n",
              " ('exemplo', 'exbemplo'),\n",
              " ('tem', 'túem'),\n",
              " ('usuário', 'usuárin'),\n",
              " ('dados', 'daáos'),\n",
              " ('python', 'pythoçn'),\n",
              " ('nossa', 'nossk'),\n",
              " ('além', 'âlém'),\n",
              " ('assim', 'aóssim'),\n",
              " ('ter', 'tãer'),\n",
              " ('até', 'vté'),\n",
              " ('bem', 'búm'),\n",
              " ('design', 'íesign'),\n",
              " ('trabalho', 'trabèalho'),\n",
              " ('foi', 'kfoi'),\n",
              " ('apenas', 'aapenas'),\n",
              " ('empresa', 'pmpresa'),\n",
              " ('valor', 'valoqr'),\n",
              " ('será', 'sçerá'),\n",
              " ('entre', 'entró'),\n",
              " ('método', 'nétodo'),\n",
              " ('precisamos', 'prefcisamos'),\n",
              " ('ainda', 'sainda'),\n",
              " ('vai', 'uai'),\n",
              " ('conteúdo', 'cĩonteúdo'),\n",
              " ('seus', 'sâus'),\n",
              " ('eu', 'ìeu'),\n",
              " ('todos', 'todás'),\n",
              " ('tempo', 'utempo'),\n",
              " ('sempre', 'sempce'),\n",
              " ('qual', 'fual'),\n",
              " ('ela', 'elal'),\n",
              " ('só', 'skó'),\n",
              " ('utilizar', 'utilĩzar'),\n",
              " ('projeto', 'proójeto'),\n",
              " ('site', 'isite'),\n",
              " ('sem', 'secm'),\n",
              " ('pelo', 'pẽlo'),\n",
              " ('alura', 'aluéa'),\n",
              " ('dia', 'dil'),\n",
              " ('tudo', 'tudy'),\n",
              " ('ela', 'qelay'),\n",
              " ('só', 'sód'),\n",
              " ('utilizar', 'dtilizacr'),\n",
              " ('projeto', 'bprojõto'),\n",
              " ('site', 'ysiteo'),\n",
              " ('sem', 'sõêm'),\n",
              " ('pelo', 'peàli'),\n",
              " ('alura', 'asuraó'),\n",
              " ('dia', 'deiìa'),\n",
              " ('tudo', 'tuĩdoì'),\n",
              " ('ela', 'eúaa'),\n",
              " ('só', 'ró'),\n",
              " ('utilizar', 'utilizẽaçr'),\n",
              " ('projeto', 'prêjetó'),\n",
              " ('site', 'sqiqte'),\n",
              " ('sem', 'sũexm'),\n",
              " ('pelo', 'pçlxo'),\n",
              " ('alura', 'uluraa'),\n",
              " ('dia', 'dĩaz'),\n",
              " ('tudo', 'kzudo'),\n",
              " ('corretor', 'correptor'),\n",
              " ('tática', 'trtica'),\n",
              " ('empoderamento', 'ewpoderamento'),\n",
              " ('linux', 'lifux'),\n",
              " ('cachorro', 'cachoçro'),\n",
              " ('gato', 'îgato'),\n",
              " ('cavalo', 'cakvalo'),\n",
              " ('relógio', 'relógiuo'),\n",
              " ('canela', 'canelac'),\n",
              " ('tênis', 'tênisy'),\n",
              " ('ansiosa', 'anciosa'),\n",
              " ('ansiosa', 'ancciosa'),\n",
              " ('ansiosa', 'ansioa'),\n",
              " ('empoderamento', 'empoderamento'),\n",
              " ('asterisco', 'asterístico'),\n",
              " ('gratuito', 'gratuíto'),\n",
              " ('entretido', 'entertido'),\n",
              " ('ritmo', 'ritimo'),\n",
              " ('idiota', 'indiota'),\n",
              " ('tomara', 'tomare'),\n",
              " ('seja', 'seje'),\n",
              " ('prevalecer', 'provalecer'),\n",
              " ('esteja', 'esteje'),\n",
              " ('mendigo', 'mindigo'),\n",
              " ('cérebro', 'célebro'),\n",
              " ('perturbar', 'pertubar')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluator(tests):\n",
        "    number_of_words = len(tests)\n",
        "    hits = 0\n",
        "    for right, wrong in tests:\n",
        "        corrected_word = checker(wrong)\n",
        "        if corrected_word == right:\n",
        "            hits += 1\n",
        "    hit_rate = round((hits*100)/number_of_words, 2)\n",
        "    print(f\"hit rate: {hit_rate} of {number_of_words}\")"
      ],
      "metadata": {
        "id": "FsUn8-2OGprb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VQOl0auNdgq",
        "outputId": "4d1b6bfb-7df4-4894-e6e3-0786a4b815b2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hit rate: 76.34 of 186\n"
          ]
        }
      ]
    }
  ]
}